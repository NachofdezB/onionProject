# @ Author: Antonio Llorente. Aitea Tech Becarios

# <antoniollorentecuenca@gmail.com>

# @ Project: Cebolla

# @ Create Time: 2025-05-05 10:30:50

# @ Modified time: 2025-09-20 10:29:59

# @ Description:This FastAPI router exposes endpoints for triggering a
# dynamic spider to scrape news articles from URLs stored in a PostgreSQL
# database and for retrieving the `result.json` file generated by the
# scraping process.The scraping operation is asynchronous, and upon completion,
# a success# message is returned. If any error occurs during scraping, a
# 500 error with a failure message is raised. Additionally, the router
# provides access to the `result.json` file, which contains the scraped data.
# If the file is not found, a 404 error is raised.

import os
from fastapi import APIRouter, Request, HTTPException
from fastapi.responses import FileResponse
from app.scraping.spider_factory import run_dynamic_spider_from_db
from loguru import logger
import asyncio

router = APIRouter(prefix="/newsSpider", tags=["News spider"])

@router.get("/scrape-news")
async def scrape_news_articles(request: Request) -> dict[str, str]:
    """
    Endpoint to start the news scraping process using the dynamic spider.

    This function:
    - Retrieves the PostgreSQL connection pool from the app state.
    - Launches the dynamic spider asynchronously in the background.
    - Returns an immediate success message while the process runs.

    Args:
        request (Request): The incoming HTTP request object, with access to
                           the app's state (DB connection pool).

    Returns:
        dict[str, str]: A dictionary with the operation status message.

    Raises:
        HTTPException: If an error occurs during scraping, a 500 status code
                       exception is raised.
    """
    try:
        pool = request.app.state.pool
        # Run the spider function asynchronously in the background
        asyncio.create_task(run_dynamic_spider_from_db(pool))
        return {"status": "âœ… News processing started"}
    except Exception as e:
        logger.error(f"Scraping failed: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Scraping failed: {str(e)}"
        )

@router.get("/result.json")
async def get_result_json():
    """
    Endpoint to retrieve the result.json file.

    This function attempts to return the `result.json` file from the server's
    file system. If the file is not found, it raises a 404 error.

    Returns:
        FileResponse: The `result.json` file if it exists.

    Raises:
        HTTPException: If the `result.json` file does not exist, a 404 status
                       code is raised.
    """
    file_path = "result.json"

    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="File not found")

    return FileResponse(file_path, media_type='application/json')